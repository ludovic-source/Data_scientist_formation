{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3011dcf2-bab8-47e9-a9c1-678e8f28d34b",
   "metadata": {},
   "source": [
    "# Réalisez une veille technique : \n",
    "*Notebook Mission 2 - Réalisez une veille technique*\n",
    "\n",
    "**Classification superviée d’images via les Visions Transformers (ViT)**\n",
    "\n",
    "Il s'agit de réaliser un POC qui met en oeuvre cette nouvelle technique avec les données image déjà exploitées dans le cadre du projet 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2878dc3b-6aee-4d5f-a091-4c748bf4a8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version 1.26.4\n",
      "pandas version 2.1.4\n",
      "matplotlib version 3.8.0\n"
     ]
    }
   ],
   "source": [
    "# fonctions personnelles pour le pré traitement des données textuelles\n",
    "import pre_treatment_text as ptt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from matplotlib.ticker import ScalarFormatter\n",
    "#from matplotlib.ticker import FuncFormatter\n",
    "#import scipy\n",
    "#from scipy import stats\n",
    "#import scipy.stats as st\n",
    "\n",
    "#import statsmodels\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "#from collections import defaultdict\n",
    "#from collections import Counter\n",
    "\n",
    "#import cv2\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from transformers import TFViTForImageClassification, ViTImageProcessor\n",
    "from transformers import TFAutoModelForImageClassification, AutoFeatureExtractor\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from transformers import AdamW\n",
    "\n",
    "#import shutil\n",
    "\n",
    "print(\"numpy version\", np.__version__)\n",
    "print(\"pandas version\", pd.__version__)\n",
    "print(\"matplotlib version\", matplotlib.__version__)\n",
    "#print(\"seaborn version\", sns.__version__)\n",
    "#print(\"scipy version\", scipy.__version__)\n",
    "#print(\"statsmodels version\", statsmodels.__version__)\n",
    "\n",
    "#print(\"sklearn version\", sklearn.__version__)\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a3783-5232-41de-8d9e-9a535008fa7b",
   "metadata": {},
   "source": [
    "## 1 - Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39b6daed-a458-498e-a993-ca8d0ed9fa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>crawl_timestamp</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category_tree</th>\n",
       "      <th>pid</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>image</th>\n",
       "      <th>is_FK_Advantage_product</th>\n",
       "      <th>description</th>\n",
       "      <th>product_rating</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_specifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/elegance-polyester-mul...</td>\n",
       "      <td>Elegance Polyester Multicolor Abstract Eyelet ...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Curtains &amp; Accessories &gt;&gt;...</td>\n",
       "      <td>CRNEG7BKMFFYHQ8Z</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Elegance Polyester Multicolor ...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Elegance</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/sathiyas-cotton-bath-t...</td>\n",
       "      <td>Sathiyas Cotton Bath Towel</td>\n",
       "      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n",
       "      <td>BTWEGFZHGBXPHZUH</td>\n",
       "      <td>600.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Specifications of Sathiyas Cotton Bath Towel (...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Sathiyas</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/eurospa-cotton-terry-f...</td>\n",
       "      <td>Eurospa Cotton Terry Face Towel Set</td>\n",
       "      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n",
       "      <td>BTWEG6SHXTDB2A2Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Eurospa Cotton Terry Face Towe...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Eurospa</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Material\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8</td>\n",
       "      <td>2016-06-20 08:49:52 +0000</td>\n",
       "      <td>http://www.flipkart.com/santosh-royal-fashion-...</td>\n",
       "      <td>SANTOSH ROYAL FASHION Cotton Printed King size...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n",
       "      <td>BDSEJT9UQWHDUBH4</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of SANTOSH ROYAL FASHION Cotton P...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>SANTOSH ROYAL FASHION</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7</td>\n",
       "      <td>2016-06-20 08:49:52 +0000</td>\n",
       "      <td>http://www.flipkart.com/jaipur-print-cotton-fl...</td>\n",
       "      <td>Jaipur Print Cotton Floral King sized Double B...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n",
       "      <td>BDSEJTHNGWVGWWQU</td>\n",
       "      <td>2599.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Jaipur Print Cotton Floral Kin...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Jaipur Print</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id            crawl_timestamp  \\\n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7  2016-04-30 03:22:56 +0000   \n",
       "1  7b72c92c2f6c40268628ec5f14c6d590  2016-04-30 03:22:56 +0000   \n",
       "2  64d5d4a258243731dc7bbb1eef49ad74  2016-04-30 03:22:56 +0000   \n",
       "3  d4684dcdc759dd9cdf41504698d737d8  2016-06-20 08:49:52 +0000   \n",
       "4  6325b6870c54cd47be6ebfbffa620ec7  2016-06-20 08:49:52 +0000   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.flipkart.com/elegance-polyester-mul...   \n",
       "1  http://www.flipkart.com/sathiyas-cotton-bath-t...   \n",
       "2  http://www.flipkart.com/eurospa-cotton-terry-f...   \n",
       "3  http://www.flipkart.com/santosh-royal-fashion-...   \n",
       "4  http://www.flipkart.com/jaipur-print-cotton-fl...   \n",
       "\n",
       "                                        product_name  \\\n",
       "0  Elegance Polyester Multicolor Abstract Eyelet ...   \n",
       "1                         Sathiyas Cotton Bath Towel   \n",
       "2                Eurospa Cotton Terry Face Towel Set   \n",
       "3  SANTOSH ROYAL FASHION Cotton Printed King size...   \n",
       "4  Jaipur Print Cotton Floral King sized Double B...   \n",
       "\n",
       "                               product_category_tree               pid  \\\n",
       "0  [\"Home Furnishing >> Curtains & Accessories >>...  CRNEG7BKMFFYHQ8Z   \n",
       "1  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEGFZHGBXPHZUH   \n",
       "2  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEG6SHXTDB2A2Y   \n",
       "3  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJT9UQWHDUBH4   \n",
       "4  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJTHNGWVGWWQU   \n",
       "\n",
       "   retail_price  discounted_price                                 image  \\\n",
       "0        1899.0             899.0  55b85ea15a1536d46b7190ad6fff8ce7.jpg   \n",
       "1         600.0             449.0  7b72c92c2f6c40268628ec5f14c6d590.jpg   \n",
       "2           NaN               NaN  64d5d4a258243731dc7bbb1eef49ad74.jpg   \n",
       "3        2699.0            1299.0  d4684dcdc759dd9cdf41504698d737d8.jpg   \n",
       "4        2599.0             698.0  6325b6870c54cd47be6ebfbffa620ec7.jpg   \n",
       "\n",
       "   is_FK_Advantage_product                                        description  \\\n",
       "0                    False  Key Features of Elegance Polyester Multicolor ...   \n",
       "1                    False  Specifications of Sathiyas Cotton Bath Towel (...   \n",
       "2                    False  Key Features of Eurospa Cotton Terry Face Towe...   \n",
       "3                    False  Key Features of SANTOSH ROYAL FASHION Cotton P...   \n",
       "4                    False  Key Features of Jaipur Print Cotton Floral Kin...   \n",
       "\n",
       "        product_rating       overall_rating                  brand  \\\n",
       "0  No rating available  No rating available               Elegance   \n",
       "1  No rating available  No rating available               Sathiyas   \n",
       "2  No rating available  No rating available                Eurospa   \n",
       "3  No rating available  No rating available  SANTOSH ROYAL FASHION   \n",
       "4  No rating available  No rating available           Jaipur Print   \n",
       "\n",
       "                              product_specifications  \n",
       "0  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...  \n",
       "1  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...  \n",
       "2  {\"product_specification\"=>[{\"key\"=>\"Material\",...  \n",
       "3  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...  \n",
       "4  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le fichier de données\n",
    "data = pd.read_csv(\"C:/Users/admin/Documents/Projets/Projet_6/data_projet/Dataset+projet+prétraitement+textes+images/Flipkart/flipkart_com-ecommerce_sample_1050.csv\", \\\n",
    "                   sep=',', low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd8ae371-64b0-4e19-986a-04c7fa036bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la méthode split sur chaque élément de la colonne\n",
    "y = data['product_category_tree'].apply(lambda x: ptt.clean_category_first_level(x))\n",
    "data['category'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "779af1dd-f3f3-4dc3-b717-7337d88f42dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>crawl_timestamp</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category_tree</th>\n",
       "      <th>pid</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>image</th>\n",
       "      <th>is_FK_Advantage_product</th>\n",
       "      <th>description</th>\n",
       "      <th>product_rating</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_specifications</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/elegance-polyester-mul...</td>\n",
       "      <td>Elegance Polyester Multicolor Abstract Eyelet ...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Curtains &amp; Accessories &gt;&gt;...</td>\n",
       "      <td>CRNEG7BKMFFYHQ8Z</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Elegance Polyester Multicolor ...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Elegance</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/sathiyas-cotton-bath-t...</td>\n",
       "      <td>Sathiyas Cotton Bath Towel</td>\n",
       "      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n",
       "      <td>BTWEGFZHGBXPHZUH</td>\n",
       "      <td>600.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Specifications of Sathiyas Cotton Bath Towel (...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Sathiyas</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/eurospa-cotton-terry-f...</td>\n",
       "      <td>Eurospa Cotton Terry Face Towel Set</td>\n",
       "      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n",
       "      <td>BTWEG6SHXTDB2A2Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Eurospa Cotton Terry Face Towe...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Eurospa</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Material\",...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8</td>\n",
       "      <td>2016-06-20 08:49:52 +0000</td>\n",
       "      <td>http://www.flipkart.com/santosh-royal-fashion-...</td>\n",
       "      <td>SANTOSH ROYAL FASHION Cotton Printed King size...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n",
       "      <td>BDSEJT9UQWHDUBH4</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of SANTOSH ROYAL FASHION Cotton P...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>SANTOSH ROYAL FASHION</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7</td>\n",
       "      <td>2016-06-20 08:49:52 +0000</td>\n",
       "      <td>http://www.flipkart.com/jaipur-print-cotton-fl...</td>\n",
       "      <td>Jaipur Print Cotton Floral King sized Double B...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n",
       "      <td>BDSEJTHNGWVGWWQU</td>\n",
       "      <td>2599.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Jaipur Print Cotton Floral Kin...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Jaipur Print</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id            crawl_timestamp  \\\n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7  2016-04-30 03:22:56 +0000   \n",
       "1  7b72c92c2f6c40268628ec5f14c6d590  2016-04-30 03:22:56 +0000   \n",
       "2  64d5d4a258243731dc7bbb1eef49ad74  2016-04-30 03:22:56 +0000   \n",
       "3  d4684dcdc759dd9cdf41504698d737d8  2016-06-20 08:49:52 +0000   \n",
       "4  6325b6870c54cd47be6ebfbffa620ec7  2016-06-20 08:49:52 +0000   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.flipkart.com/elegance-polyester-mul...   \n",
       "1  http://www.flipkart.com/sathiyas-cotton-bath-t...   \n",
       "2  http://www.flipkart.com/eurospa-cotton-terry-f...   \n",
       "3  http://www.flipkart.com/santosh-royal-fashion-...   \n",
       "4  http://www.flipkart.com/jaipur-print-cotton-fl...   \n",
       "\n",
       "                                        product_name  \\\n",
       "0  Elegance Polyester Multicolor Abstract Eyelet ...   \n",
       "1                         Sathiyas Cotton Bath Towel   \n",
       "2                Eurospa Cotton Terry Face Towel Set   \n",
       "3  SANTOSH ROYAL FASHION Cotton Printed King size...   \n",
       "4  Jaipur Print Cotton Floral King sized Double B...   \n",
       "\n",
       "                               product_category_tree               pid  \\\n",
       "0  [\"Home Furnishing >> Curtains & Accessories >>...  CRNEG7BKMFFYHQ8Z   \n",
       "1  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEGFZHGBXPHZUH   \n",
       "2  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEG6SHXTDB2A2Y   \n",
       "3  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJT9UQWHDUBH4   \n",
       "4  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJTHNGWVGWWQU   \n",
       "\n",
       "   retail_price  discounted_price                                 image  \\\n",
       "0        1899.0             899.0  55b85ea15a1536d46b7190ad6fff8ce7.jpg   \n",
       "1         600.0             449.0  7b72c92c2f6c40268628ec5f14c6d590.jpg   \n",
       "2           NaN               NaN  64d5d4a258243731dc7bbb1eef49ad74.jpg   \n",
       "3        2699.0            1299.0  d4684dcdc759dd9cdf41504698d737d8.jpg   \n",
       "4        2599.0             698.0  6325b6870c54cd47be6ebfbffa620ec7.jpg   \n",
       "\n",
       "   is_FK_Advantage_product                                        description  \\\n",
       "0                    False  Key Features of Elegance Polyester Multicolor ...   \n",
       "1                    False  Specifications of Sathiyas Cotton Bath Towel (...   \n",
       "2                    False  Key Features of Eurospa Cotton Terry Face Towe...   \n",
       "3                    False  Key Features of SANTOSH ROYAL FASHION Cotton P...   \n",
       "4                    False  Key Features of Jaipur Print Cotton Floral Kin...   \n",
       "\n",
       "        product_rating       overall_rating                  brand  \\\n",
       "0  No rating available  No rating available               Elegance   \n",
       "1  No rating available  No rating available               Sathiyas   \n",
       "2  No rating available  No rating available                Eurospa   \n",
       "3  No rating available  No rating available  SANTOSH ROYAL FASHION   \n",
       "4  No rating available  No rating available           Jaipur Print   \n",
       "\n",
       "                              product_specifications         category  \n",
       "0  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...  Home Furnishing  \n",
       "1  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...        Baby Care  \n",
       "2  {\"product_specification\"=>[{\"key\"=>\"Material\",...        Baby Care  \n",
       "3  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...  Home Furnishing  \n",
       "4  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...  Home Furnishing  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b59e95-eae5-4a93-a5e2-ca40bd890737",
   "metadata": {},
   "source": [
    "**Créons les dataset d'entrainement, de validation et de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "07b61b23-5002-4aef-bbbf-e834996fd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_fct(path, validation_split=0, data_type=None) :\n",
    "    \"\"\"\n",
    "        path : Chemin du dossier contenant les images organisées en sous-dossiers par classe.\n",
    "        validation_split : Pourcentage du dataset à utiliser pour la validation (ex. 0.2 pour 20%).\n",
    "        data_type : Détermine si on charge les données d'entraînement (\"training\") ou de validation (\"validation\").\n",
    "    \"\"\"\n",
    "\n",
    "    #  Création du dataset\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "                    path, labels='inferred', label_mode='categorical',\n",
    "                    class_names=None, batch_size=batch_size, image_size=(224, 224), shuffle=True, seed=42,\n",
    "                    validation_split=validation_split, subset=data_type\n",
    "                    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "426a0f52-3ec2-42d1-a7c9-ac25b44bcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "path = \"C:/Users/admin/Documents/Projets/Projet_6/data_projet/Flipkart/images_per_category\"\n",
    "path_test = \"C:/Users/admin/Documents/Projets/Projet_6/data_projet/Flipkart/images_per_category_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c87b5f7-7412-4d82-8f87-6e2dac12dc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 787 files belonging to 7 classes.\n",
      "Using 591 files for training.\n",
      "Found 787 files belonging to 7 classes.\n",
      "Using 196 files for validation.\n",
      "Found 263 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_fct(path, validation_split=0.25, data_type='training')\n",
    "dataset_val = dataset_fct(path, validation_split=0.25, data_type='validation')\n",
    "dataset_test = dataset_fct(path_test, validation_split=0, data_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc601dc8-688c-45d8-9c20-491f889e29a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Charger un batch d'exemple\n",
    "for image_batch, label_batch in dataset_train.take(1):\n",
    "    print(image_batch.shape)  # Afficher la forme du batch d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795a575-d8cc-47ad-b0d2-76893051e5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1417098-14f8-4574-9817-21e5c27b96d9",
   "metadata": {},
   "source": [
    "## 2 - Classifier les images\n",
    "\n",
    "solution pour préparer vos données pour un modèle Vision Transformer (ViT) en utilisant TensorFlow et Hugging Face.\n",
    "\n",
    "Solution\n",
    "Nous allons suivre ces étapes pour charger les images, les prétraiter, puis entraîner un modèle ViT sur les données :\n",
    "\n",
    "Charger les données à partir des dossiers : Utiliser la fonction image_dataset_from_directory de TensorFlow pour charger les images à partir des sous-dossiers par catégorie.\n",
    "\n",
    "Prétraitement des images : Utiliser le ViTFeatureExtractor de Hugging Face pour adapter les images aux exigences du modèle ViT.\n",
    "\n",
    "Création du modèle ViT : Charger un modèle ViT pré-entraîné pour la classification d'images et l'adapter pour l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "addf3c60-fff9-44c7-84df-5feaf34f2e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 787 files belonging to 7 classes.\n",
      "Found 263 files belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4952\\2941086337.py\", line 40, in None  *\n        lambda x, y: (preprocess_vit(x), y)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4952\\3060344274.py\", line 19, in preprocess_vit\n        inputs = feature_extractor(images=image, return_tensors=\"tf\")\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\image_processing_utils.py\", line 41, in __call__\n        return self.preprocess(images, **kwargs)\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py\", line 854, in wrapper\n        return func(*args, **valid_kwargs)\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\models\\vit\\image_processing_vit.py\", line 226, in preprocess\n        images = make_list_of_images(images)\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\image_utils.py\", line 196, in make_list_of_images\n        images = list(images)\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 40\u001b[0m\n\u001b[0;32m     31\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m image_dataset_from_directory(\n\u001b[0;32m     32\u001b[0m     test_dir,\n\u001b[0;32m     33\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Application du prétraitement aux datasets\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (preprocess_vit(x), y), num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m     41\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (preprocess_vit(x), y), num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Chargement du modèle ViT pré-entraîné pour la classification d'images\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2341\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_op\u001b[38;5;241m.\u001b[39m_map_v2(\n\u001b[0;32m   2342\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2343\u001b[0m     map_func,\n\u001b[0;32m   2344\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[0;32m   2345\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[0;32m   2346\u001b[0m     synchronous\u001b[38;5;241m=\u001b[39msynchronous,\n\u001b[0;32m   2347\u001b[0m     use_unbounded_threadpool\u001b[38;5;241m=\u001b[39muse_unbounded_threadpool,\n\u001b[0;32m   2348\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2349\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:57\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`synchronous` is not supported with `num_parallel_calls`, but\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `num_parallel_calls` was set to \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m       num_parallel_calls,\n\u001b[0;32m     56\u001b[0m   )\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     58\u001b[0m     input_dataset,\n\u001b[0;32m     59\u001b[0m     map_func,\n\u001b[0;32m     60\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[0;32m     61\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[0;32m     62\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     63\u001b[0m     use_unbounded_threadpool\u001b[38;5;241m=\u001b[39muse_unbounded_threadpool,\n\u001b[0;32m     64\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:202\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, use_unbounded_threadpool, name)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m structured_function\u001b[38;5;241m.\u001b[39mStructuredFunctionWrapper(\n\u001b[0;32m    203\u001b[0m     map_func,\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_name(),\n\u001b[0;32m    205\u001b[0m     dataset\u001b[38;5;241m=\u001b[39minput_dataset,\n\u001b[0;32m    206\u001b[0m     use_legacy_function\u001b[38;5;241m=\u001b[39muse_legacy_function)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m fn_factory()\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(args, kwargs, add_initializers_to\u001b[38;5;241m=\u001b[39minitializers)\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    694\u001b[0m )\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[0;32m    697\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    698\u001b[0m )\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[0;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[0;32m    180\u001b[0m   )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[0;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[0;32m    285\u001b[0m )\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[0;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[0;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[0;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[0;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    320\u001b[0m )\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m wrapper_helper(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, ag_ctx)(\u001b[38;5;241m*\u001b[39mnested_args)\n\u001b[0;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4952\\2941086337.py\", line 40, in None  *\n        lambda x, y: (preprocess_vit(x), y)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4952\\3060344274.py\", line 19, in preprocess_vit\n        inputs = feature_extractor(images=image, return_tensors=\"tf\")\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\image_processing_utils.py\", line 41, in __call__\n        return self.preprocess(images, **kwargs)\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py\", line 854, in wrapper\n        return func(*args, **valid_kwargs)\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\models\\vit\\image_processing_vit.py\", line 226, in preprocess\n        images = make_list_of_images(images)\n    File \"C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\transformers\\image_utils.py\", line 196, in make_list_of_images\n        images = list(images)\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForImageClassification, AdamWeightDecay, AutoImageProcessor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Définir le chemin vers les dossiers contenant les images\n",
    "train_dir = \"C:/Users/admin/Documents/Projets/Projet_6/data_projet/Flipkart/images_per_category\"\n",
    "test_dir = \"C:/Users/admin/Documents/Projets/Projet_6/data_projet/Flipkart/images_per_category_test\"\n",
    "\n",
    "# Chargement de l'extracteur de caractéristiques pour ViT\n",
    "feature_extractor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "# Fonction de prétraitement des images pour ViT avec @tf.function pour optimiser le graph\n",
    "@tf.function\n",
    "def preprocess_vit(image):\n",
    "    # Normalisation de l'image\n",
    "    image = image / 255.0\n",
    "    # Extraction des caractéristiques de l'image avec le feature_extractor\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"tf\")\n",
    "    return inputs['pixel_values']\n",
    "\n",
    "# Chargement des datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode=\"int\",  # Utiliser \"int\" pour une classification des labels\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode=\"int\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Application du prétraitement aux datasets\n",
    "train_dataset = train_dataset.map(lambda x, y: (preprocess_vit(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(lambda x, y: (preprocess_vit(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Chargement du modèle ViT pré-entraîné pour la classification d'images\n",
    "model = TFAutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=7)\n",
    "\n",
    "# Compiler le modèle avec l'optimiseur AdamW et la fonction de perte SparseCategoricalCrossentropy\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset)\n",
    "\n",
    "# Évaluation du modèle sur les données de validation\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Perte : {loss:.4f}, Précision : {accuracy:.4%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a97bed-4696-425e-ab13-9928833e45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = final_model.evaluate(val_dataset)\n",
    "print(f\"Perte : {loss:.4f}, Précision : {accuracy:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c58b7-118d-4bea-9f7c-409e21a1517d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
