{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08484c74-62f5-4a0a-9fec-118009d632da",
   "metadata": {},
   "source": [
    "# Classifiez automatiquement des biens de consommation : \n",
    "*Notebook mission 2 - Réalisez une classification supervisée d'images*\n",
    "\n",
    "**Classification superviée d’images via CNN Transfer Learning**\n",
    "\n",
    "Pourrais-tu réaliser une classification supervisée à partir des images ? Je souhaiterais que tu mettes en place une data augmentation afin d’optimiser le modèle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0705892-063b-4da3-af90-d5167634cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import scipy.stats as st\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# pour l'ACP\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import timeit\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "print(\"numpy version\", np.__version__)\n",
    "print(\"pandas version\", pd.__version__)\n",
    "print(\"matplotlib version\", matplotlib.__version__)\n",
    "print(\"seaborn version\", sns.__version__)\n",
    "print(\"scipy version\", scipy.__version__)\n",
    "print(\"statsmodels version\", statsmodels.__version__)\n",
    "\n",
    "print(\"sklearn version\", sklearn.__version__)\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0b909-c574-42a3-b550-14333129fd7f",
   "metadata": {},
   "source": [
    "## 1 - Création du modèle de classification\n",
    "\n",
    "- Charge le modèle pré-entraîné VGG16\n",
    "  \n",
    "  + include_top=False : Supprime les couches de classification de VGG16.\n",
    "  + weights=\"imagenet\" : Charge les poids pré-entraînés sur ImageNet.\n",
    "  + input_shape=(224, 224, 3) : Définit l’entrée du réseau pour des images couleur de 224×224 pixels.\n",
    "\n",
    "- Gèle les couches du modèle pré-entraîné\n",
    "\n",
    "  + Empêche la modification des poids de VGG16 pendant l'entraînement.\n",
    "  + Seules les couches ajoutées seront entraînées.\n",
    "\n",
    "- Ajoute des couches supplémentaires\n",
    "\n",
    "  + GlobalAveragePooling2D : Réduit la dimension de sortie sans trop de paramètres.\n",
    "  + Dense(256, activation='relu') : Ajoute une couche entièrement connectée.\n",
    "  + Dropout(0.5) : Réduit le risque d'overfitting en désactivant 50% des neurones.\n",
    "  + Dense(4, activation='softmax') : La dernière couche de classification avec 7 classes.\n",
    "\n",
    "- Crée et compile le modèle\n",
    "\n",
    "  + Définit le modèle final avec comme entrée VGG16 et comme sortie la nouvelle couche de classification.\n",
    "  + Compile le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8b9af-8afd-4862-981f-c0505ec0b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fct() :\n",
    "    # Récupération modèle pré-entraîné\n",
    "    model0 = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "    # Layer non entraînables = on garde les poids du modèle pré-entraîné\n",
    "    for layer in model0.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Récupérer la sortie de ce réseau\n",
    "    x = model0.output\n",
    "    # Compléter le modèle\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "    # Définir le nouveau modèle\n",
    "    model = Model(inputs=model0.input, outputs=predictions)\n",
    "    # compilation du modèle\n",
    "    # loss=\"categorical_crossentropy\" → Adapté pour un problème de classification multi-classes.\n",
    "    # optimizer='rmsprop' → Optimiseur recommandé pour le fine-tuning.\n",
    "    # metrics=[\"accuracy\"] → Suit la précision du modèle.\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dc7a62-97b1-49e6-9e3d-2847f7ae672e",
   "metadata": {},
   "source": [
    "## 2 - Approche nouvelle par Dataset avec data augmentation intégrée au modèle\n",
    "\n",
    "L’approche nouvelle par dataset avec data augmentation intégrée au modèle désigne une méthode dans laquelle l'augmentation des données (data augmentation) est effectuée directement dans le pipeline du modèle, plutôt que d’être réalisée en amont (par prétraitement des images).\n",
    "\n",
    "- Data Augmentation = technique permettant d’augmenter artificiellement la taille et la diversité d’un dataset en appliquant des transformations (rotation, zoom, bruit, etc.) sur les images d’entraînement. Cela améliore la généralisation du modèle et réduit le surapprentissage (overfitting).\n",
    "\n",
    "- Intégrée au Modèle = l’augmentation des données n’est pas faite en prétraitement (offline) mais au moment de l'entraînement, via des couches spécifiques ou un pipeline de traitement dynamique.\n",
    "\n",
    "Avantages :\n",
    "- Gain de temps : Pas besoin de stocker un grand volume de données augmentées.\n",
    "- Flexibilité : Les transformations sont appliquées différemment à chaque époque d'entraînement.\n",
    "- Optimisation mémoire : Les images sont augmentées à la volée, ce qui évite de stocker une grande base de données augmentée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b35108-0425-4650-853a-880ca43103f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0e8ae-e1a4-451c-9f8d-092afc5630ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87000d69-02a3-4dd3-9419-48d5deacfcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
