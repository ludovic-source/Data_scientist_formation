{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a961411-0aa5-4ce6-80b5-d475c6614b40",
   "metadata": {},
   "source": [
    "# Impl√©mentez un mod√®le de scoring\n",
    "\n",
    "*Notebook mod√©lisation*\n",
    "\n",
    "L‚Äôentreprise souhaite mettre en ≈ìuvre un outil de ‚Äúscoring cr√©dit‚Äù pour calculer la probabilit√© qu‚Äôun client rembourse son cr√©dit, puis classifie la demande en cr√©dit accord√© ou refus√©. Elle souhaite donc d√©velopper un algorithme de classification en s‚Äôappuyant sur des sources de donn√©es vari√©es (donn√©es comportementales, donn√©es provenant d'autres institutions financi√®res, etc.).\n",
    "\n",
    "**Mission :**\n",
    "\n",
    "- Construire un mod√®le de scoring qui donnera une pr√©diction sur la probabilit√© de faillite d'un client de fa√ßon automatique.\n",
    "\n",
    "- Analyser les features qui contribuent le plus au mod√®le, d‚Äôune mani√®re g√©n√©rale (feature importance globale) et au niveau d‚Äôun client (feature importance locale), afin, dans un soucis de transparence, de permettre √† un charg√© d‚Äô√©tudes de mieux comprendre le score attribu√© par le mod√®le.\n",
    "\n",
    "- Mettre en production le mod√®le de scoring de pr√©diction √† l‚Äôaide d‚Äôune API et r√©aliser une interface de test de cette API.\n",
    "\n",
    "- Mettre en ≈ìuvre une approche globale MLOps de bout en bout, du tracking des exp√©rimentations √† l‚Äôanalyse en production du data drift.\n",
    "    + Dans le notebook d‚Äôentra√Ænement des mod√®les, g√©n√©rer √† l‚Äôaide de MLFlow un tracking d'exp√©rimentations\n",
    "    + Lancer l‚Äôinterface web 'UI MLFlow\" d'affichage des r√©sultats du tracking\n",
    "    + R√©aliser avec MLFlow un stockage centralis√© des mod√®les dans un ‚Äúmodel registry‚Äù\n",
    "    + Tester le serving MLFlow\n",
    "    + G√©rer le code avec le logiciel de version Git\n",
    "    + Partager le code sur Github pour assurer une int√©gration continue\n",
    "    + Utiliser Github Actions pour le d√©ploiement continu et automatis√© du code de l‚ÄôAPI sur le cloud\n",
    "    + Concevoir des tests unitaires avec Pytest (ou Unittest) et les ex√©cuter de mani√®re automatis√©e lors du build r√©alis√© par Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075208bc-0fc6-4f94-816a-6b785c17de4d",
   "metadata": {},
   "source": [
    "## 1 - Pr√©parer l'environnement d'exp√©rimentation\n",
    "\n",
    "### 1.1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bc62f7-f6f2-4e72-9de2-92187b3730a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version 1.26.4\n",
      "pandas version 2.1.4\n",
      "mlflow version 2.20.1\n",
      "sklearn version 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.tracking\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "print(\"numpy version\", np.__version__)\n",
    "print(\"pandas version\", pd.__version__)\n",
    "print(\"mlflow version\", mlflow.__version__)\n",
    "print(\"sklearn version\", sklearn.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee8c9e-e291-43c7-9d00-e9084f5fd3cb",
   "metadata": {},
   "source": [
    "### 1.2 - Lancement du serveur MLFlow\n",
    "\n",
    "Dans le terminal de Powershell Prompt d'Anaconda, lancer cette instruction :\n",
    "\n",
    "mlflow server --host 127.0.0.1 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns\n",
    "\n",
    "Cette commande permet de :\n",
    "- Stocker les m√©tadonn√©es du Model Registry dans une base de donn√©es locale SQLite.\n",
    "- Stocker les artefacts (mod√®les, fichiers) en local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c481534-9c18-4b31-a0cd-94af8ff0fa9d",
   "metadata": {},
   "source": [
    "### 1.3 - Initialisation du Tracking MLFlow de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e772755d-867c-40db-b092-46c9b31c4620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quiet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ignorer Git\n",
    "os.environ['GIT_PYTHON_REFRESH'] = 'quiet'\n",
    "\n",
    "# V√©rification si la variable d'environnement est bien d√©finie\n",
    "print(os.environ.get('GIT_PYTHON_REFRESH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841d7eb5-f0da-41ed-84c6-4329f85440ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 11:21:08 INFO mlflow.tracking.fluent: Experiment with name 'modele_test_quickstart_0' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/admin/mlruns/6', creation_time=1738837268010, experiment_id='6', last_update_time=1738837268010, lifecycle_stage='active', name='modele_test_quickstart_0', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©finir le serveur de tracking (local ou distant) - ici local\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# D√©marrer une nouvelle exp√©rimentation\n",
    "mlflow.set_experiment(\"modele_test_quickstart_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f986afe-4c78-46af-8b21-e2a63bffac7d",
   "metadata": {},
   "source": [
    "### 1.4 - Cr√©ation d'un mod√®le pour tester l'initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c0ccf8-5e7e-4ef7-b943-1878e53ac01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es Iris (pour la d√©monstration)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Diviser les donn√©es en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "# Initialiser le mod√®le\n",
    "model = LogisticRegression(**params)\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "model.fit(X_train, y_train)\n",
    "    \n",
    "# Faire des pr√©dictions sur le jeu de test\n",
    "y_pred = model.predict(X_test)\n",
    "#y_pred_prob = model.predict_proba(X_test)[:, 1]  # Probabilit√©s pour AUC binaire\n",
    "y_pred_prob = model.predict_proba(X_test)  # Probabilit√©s pour AUC\n",
    "\n",
    "# Calculer accuracy et AUC\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# auc = roc_auc_score(y_test, y_pred_prob) --> si le probl√®me √©tait binaire\n",
    "auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c39d9-6c03-4dcf-9fbd-43364367497a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb46ea0b-376d-4aa7-a8bd-9ac938f29acd",
   "metadata": {},
   "source": [
    "### 1.5 - Enregistrer le mod√®le et ses m√©tadonn√©es dans MLflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12888b4a-82c5-4ee6-9f7a-f6f04956c922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fe9aa8eba4428ea2153c77d276d7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'modele_test_quickstart_0'.\n",
      "2025/02/06 11:21:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: modele_test_quickstart_0, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "AUC: 1.0\n",
      "üèÉ View run traveling-hound-667 at: http://127.0.0.1:5000/#/experiments/6/runs/0134799111874d9ea53676b7c53eea3a\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/6\n",
      "Mod√®le enregistr√© en version 2.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'modele_test_quickstart_0'.\n"
     ]
    }
   ],
   "source": [
    "# D√©marrer une exp√©rimentation dans MLflow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Loguer les m√©triques\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Loguer le mod√®le\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"iris_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"modele_test_quickstart_0\",\n",
    "    )\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "# Ajouter au Model Registry\n",
    "#model_version = mlflow.register_model(model_info.model_uri, \"test_init_quickstart\")\n",
    "\n",
    "print(f\"Mod√®le enregistr√© en version {model_info.mlflow_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58189916-d237-4fdf-82c8-d53a23217a7b",
   "metadata": {},
   "source": [
    "**Lister les versions du mod√®le**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7622021-f2a4-4603-9129-a7a7b69b51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 1, Statut: None\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "versions = client.get_latest_versions(\"modele_test_quickstart_0\")\n",
    "for v in versions:\n",
    "    print(f\"Version: {v.version}, Statut: {v.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655614e-33ec-4644-b3db-e8dc85e91f47",
   "metadata": {},
   "source": [
    "### 1.6 - Chargez le mod√®le en tant que fonction Python, et l'utiliser pour une pr√©diction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2733cdc8-1a84-478f-8499-beb80520e516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                6.1               2.8                4.7               1.2   \n",
       "1                5.7               3.8                1.7               0.3   \n",
       "2                7.7               2.6                6.9               2.3   \n",
       "3                6.0               2.9                4.5               1.5   \n",
       "\n",
       "   actual_class  predicted_class  \n",
       "0             1                1  \n",
       "1             0                0  \n",
       "2             2                2  \n",
       "3             1                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the model back for predictions as a generic Python Function model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de775f74-9975-49af-8ae2-8978b3f255c3",
   "metadata": {},
   "source": [
    "### 1.7 - Lancement de l'UI\n",
    "\n",
    "Pour  la visualisation et la comparaison des exp√©rimentations, ainsi que le stockage de mani√®re centralis√©e des mod√®les.\n",
    "\n",
    "Cliquer sur ce lien : http://127.0.0.1:5000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3a20b-14c6-4a82-96e6-5e3b8634b177",
   "metadata": {},
   "source": [
    "### 1.8 - Initialisation du Tracking MLFlow de la mission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45097d93-a9ba-4896-a772-c7b8d28781d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le serveur de tracking (local ou distant) - ici local\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# D√©marrer une nouvelle exp√©rimentation\n",
    "mlflow.set_experiment(\"modele_scoring\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
